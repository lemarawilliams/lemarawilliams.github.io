---
---

@article{masterthesis2024,
   title={Visualizing Temporal Topic Embeddings with a Compass},
   volume={31},
   ISSN={2160-9306},
   url={http://dx.doi.org/10.1109/TVCG.2024.3456143},
   DOI={10.1109/tvcg.2024.3456143},
   number={1},
   journal={IEEE Transactions on Visualization and Computer Graphics},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Palamarchuk, Daniel and Williams, Lemara and Mayer, Brian and Danielson, Thomas and Faust, Rebecca and Deschaine, Larry and North, Chris},
   year={2025},
   selected={true},
   month=jan, pages={272–282} 
   }

@inproceedings{responsibleprompting2024,
author = {Santana, Vagner Figueredo de and Berger, Sara E and Candello, Heloisa and Machado, Tiago and Sanctos, Cassia Sampaio and Su, Tianyu and Williams, Lemara},
title = {Responsible Prompting Recommendation: Fostering Responsible AI Practices in Prompting-Time},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713365},
doi = {10.1145/3706598.3713365},
abstract = {Human-Computer Interaction practitioners have been proposing best practices in user interface design for decades. However, generative Artificial Intelligence (GenAI) brings additional design considerations and currently lacks sufficient user guidance regarding affordances, inputs, and outputs. In this context, we developed a recommender system to promote responsible AI (RAI) practices while people prompt GenAI systems. We detail 10 interviews with IT professionals, the resulting recommender system developed, and 20 user sessions with IT professionals interacting with our prompt recommendations. Results indicate that responsible prompting recommendations have the potential to support novice prompt engineers and raise awareness about RAI in prompting-time. They also suggest that recommendations should simultaneously maximize both a prompt’s similarity to a user’s input as well as a diversity of associated social values provided. These findings contribute to RAI by offering practical ways to provide user guidance and enrich human-GenAI interaction via prompt recommendations.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {836},
numpages = {30},
keywords = {Prompt Engineering, Human-AI Interaction, Responsible Computing, Responsible AI, Responsible Prompting, Recommender Systems, Proactive Value Alignment},
location = {
},
series = {CHI '25},
selected = {true}
}

@inproceedings{10.1145/3708359.3712137,
author = {Santana, Vagner Figueredo de and Berger, Sara and Machado, Tiago and de Macedo, Maysa Malfiza Garcia and Sanctos, Cassia Sampaio and Williams, Lemara and Wu, Zhaoqing},
title = {Can LLMs Recommend More Responsible Prompts?},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712137},
doi = {10.1145/3708359.3712137},
abstract = {Human-Computer Interaction practitioners have been proposing best practices in user interface design for decades. However, generative Artificial Intelligence (GenAI) brings additional design considerations and currently lacks sufficient user guidance regarding affordances, inputs, and outputs. In this context, we developed a recommender system to promote responsible AI (RAI) practices while people prompt GenAI systems, by recommending addition of sentences based on social values and removal of harmful sentences. We detail a lightweight recommender system designed to be used in prompting-time and compare its recommendations to the ones provided by three base large language models (LLMs) and two LLMs fine-tuned for the task, i.e., recommending inclusion of sentences based on social values and removal of harmful sentences from a given prompt. Results indicate that our approach has the best F1-score balance in terms of recommendations for additions and removal of sentences to promote responsible prompts, while a fine-tuned model obtained the best F1-score for additions, and our approach obtained the best F1-score for removals of harmful sentences. In addition, fine-tuned models improved the objectiveness of responses by reducing the verbosity of generated content in 93\% when compared to the content generated by base models. Presented findings contribute to RAI by showing the limits and bias of existing LLMs in terms of recommendations on how to create more responsible prompts and how open-source technologies can fill this gap in prompting-time.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {298–313},
numpages = {16},
keywords = {Prompt Engineering, Responsible Prompting, Responsible AI, Recommender Systems, Recommendation Systems},
location = {
},
series = {IUI '25},
selected = {true}
}